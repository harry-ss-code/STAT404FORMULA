{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc11f26-3ab1-465b-baa6-67e78d4ff189",
   "metadata": {},
   "source": [
    "* Bayes formula states $$P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{P(B|A_1)P(A_1)+P(B|A_2)P(A_2)+P(B|A_3)P(A_3)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74139ad4-4f85-41d3-ab6f-ff59903bdd9c",
   "metadata": {},
   "source": [
    "### Sample mean and variance\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\bar y_n \n",
    "&=&\n",
    " (y_1 + y_2 + \\cdots + y_n)/n = n^{-1} \\sum_{i=1}^n y_i;\\\\\n",
    "s_n^2 \n",
    "&=&\n",
    " \\{ (y_1 - \\bar y)^2 + (y_2 - \\bar y)^2 + \\cdots + (y_n - \\bar y)^2 \\}/(n-1)\n",
    "= (n-1)^{-1}  \\sum_{i=1}^n (y_i - \\bar y)^2.\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac784a-8040-4604-91a9-1e0228af301e",
   "metadata": {},
   "source": [
    "### Population mean and variance\n",
    "\n",
    "Suppose $\\mu = E(Y)$ and $\\sigma^2 = Var(Y)$.\n",
    "We have\n",
    "\\begin{eqnarray*}\n",
    "E(\\bar{y}_n) &=&\n",
    "n^{-1} \\sum_{i=1}^n E (y_i) = \\mu;\\\\\n",
    "Var(\\bar y_n) &=&\n",
    "n^{-2} \\sum_{i=1}^n Var(y_i) = \\sigma^2/n\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa501d1-2303-4cf2-88d1-1f3f5012d0d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample variance\n",
    "\n",
    "We may find sample variance is also given by\n",
    "$$\n",
    "s^2 = \\mbox{average of } \\{ (y_i - y_j)^2/2\\}  \\mbox{ for } i \\neq j\n",
    "$$\n",
    "Trust me for the moment.\n",
    "\n",
    "It is seen that\n",
    "$$\n",
    "E\\{ (y_1 - y_2)^2\\} = Var(y_1) + Var(y_2) = 2 \\sigma^2.\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "E (s^2) = \\{ \\mbox{average of } E \\{ (y_i - y_j)^2/2\\}  \\mbox{ for } i \\neq j \\} = \\sigma^2.\n",
    "$$\n",
    "\n",
    "Because of this, we say $s^2$ is an unbiased estimator of $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de2e2e-85d4-4363-bd44-b286b27c9567",
   "metadata": {},
   "source": [
    "### Sample variance algebra\n",
    "\n",
    "In words: the sample variance $s^2$ \n",
    "is the average squared difference between observations.\n",
    "\n",
    "To prove this claim, we note\n",
    "\\begin{eqnarray*}\n",
    "\\sum_{i, j} (y_i - y_j)^2 \n",
    "&=&\n",
    "\\sum_{i, j} \\{  (y_i - \\bar y) - (y_j - \\bar y)\\}^2\\\\\n",
    "&=&\n",
    "n \\sum_{i} (y_i - \\bar y)^2 + n \\sum_{j} (y_j - \\bar y)^2 - 2 \\sum_{i,j}(y_i - \\bar y)(y_j - \\bar y).\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Not too hardly,\n",
    "$$\n",
    " \\sum_{i,j}(y_i - \\bar y)(y_j - \\bar y) = 0.\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "\\frac{1}{n(n-1)} \\sum_{i, j} (y_i - y_j)^2 \n",
    " =\n",
    "\\frac{1}{n-1}  \\sum_{i} (y_i - \\bar y)^2 + \\frac{1}{n-1}  \\sum_{j} (y_j - \\bar y)^2 \n",
    "=\n",
    "2 s^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe957c3-10d1-48ad-9a3e-f23c7c6df511",
   "metadata": {},
   "source": [
    "### Sample variance algebra\n",
    "\n",
    "Also take note\n",
    "$$\n",
    "\\sum_i (y_i - \\bar y)^2\n",
    "=\n",
    "\\sum_i (y_i^2 - 2 y_i \\bar y + \\bar y^2)\n",
    "=\n",
    "\\sum_i (y_i^2 )  - 2 \\bar y \\sum_i y_i + n \\bar y^2\n",
    "=\n",
    "\\sum_i (y_i^2 )  - 2 n \\bar y^2 + n \\bar y^2 =\n",
    "\\sum_i y_i^2   - n \\bar y^2.\n",
    "$$\n",
    "\n",
    "We get\n",
    "$$\n",
    " \\sum_i (y_i - \\bar y)^2\n",
    "= \\sum_i y_i^2   - n \\bar y^2\n",
    "$$\n",
    "and\n",
    "$$\n",
    " \\sum_i y_i^2 \n",
    "=\\sum_i (y_i - \\bar y)^2\n",
    "+ n \\bar y^2.\n",
    "$$\n",
    " \n",
    "The sum of squares formulas will be used\n",
    "very often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba5029-f8cd-4d80-835d-0fcb50760e2e",
   "metadata": {},
   "source": [
    "## Point estimation\n",
    "\n",
    "#### It is our educated and data supported guess of what ${\\mathbf \\beta}$ value is.\n",
    "\n",
    "#### The only requirement for an estimator is: it is a function of data.\n",
    "\n",
    "\n",
    "One way of estimating ${\\mathbf \\beta}$ is to use the value $\\hat {\\mathbf \\beta}$ that minimizes\n",
    "$$\n",
    " ({\\bf y} - {\\bf X} {\\mathbf \\beta})^T ({\\bf y} - {\\bf X} {\\mathbf \\beta}) \n",
    " = \\sum_{i=1}^N (y_i - {\\bf x_i} {\\mathbf \\beta})^2.\n",
    "$$\n",
    "\n",
    "The optimization solution is given by\n",
    "$$\n",
    " \\hat {\\mathbf \\beta} = ( {\\bf X}^T  {\\bf X})^{-1}  {\\bf X}^T {\\bf y}.\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fead527-16d5-48a9-a900-4807b4c7daca",
   "metadata": {},
   "source": [
    "### Some terminologies\n",
    "\n",
    "* We call $ {\\bf r} = {\\bf y} - {\\bf X} \\hat {\\mathbf \\beta}~$ **residuals**;\n",
    "\n",
    "\n",
    "* We call\n",
    "$\\hat {\\bf y} = {\\bf X} \\hat {\\mathbf \\beta}~$ **fitted values**;\n",
    "\n",
    "\n",
    "* We call $\\hat {\\mathbf \\beta}~$ the **least squares estimate**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e710475e-4d3d-44ec-b598-4a02d1897429",
   "metadata": {},
   "source": [
    "## Confidence Intervals/Prediction Intervals\n",
    "\n",
    "Suppose the model is suitable.\n",
    "\n",
    "* Our best guess of the expected $y$ value at ${\\bf x}$ is ${\\bf x} \\hat{\\mathbf \\beta}$: the fitted value.\n",
    "\n",
    "\n",
    "* A 95% CI for $\\hat{y} = {\\bf x} \\hat{\\mathbf \\beta}$ is \n",
    "\n",
    "$$\n",
    "{\\bf x} \\hat{\\mathbf \\beta} \\pm \n",
    "t_{n-k-1, 0.975} \\sqrt{var({\\bf x} \\hat{\\mathbf \\beta})}.\n",
    "$$\n",
    "\n",
    "where $t_{n-k-1, 0.975}$ the 97.5% \n",
    "quantile of the t-distribution with $n-k-1$ degrees of freedom and\n",
    "\n",
    "$$\n",
    "var({\\bf x} \\hat{\\mathbf \\beta}) \n",
    "= {\\bf x}({\\bf X}^T{\\bf X})^{-1}{\\bf x}^T \\hat{\\sigma}^2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbfcd5-7f4d-42fc-b47e-7a58c405b0e3",
   "metadata": {},
   "source": [
    "$$\n",
    "var(\\hat{\\mathbf \\beta}{\\bf_j} ) \n",
    "= ({\\bf X}^T{\\bf X})_{jj}^{-1} \\hat{\\sigma}^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae759e-f8ec-4c87-aad3-4bf05ab3c724",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\bf y} = x \\hat{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd5b4b-27f9-4402-8ecc-108634183ea4",
   "metadata": {},
   "source": [
    "* 95\\% prediction interval for $y|x$:\n",
    "$$\n",
    "\\hat y \\pm t_{N-k-1,0.975}\\sqrt{(1+x(\\mathbf{X}^T\\mathbf{X})^{-1}x^T)\\hat\\sigma^2} = \\hat y \\pm t_{N-k-1,0.975}\\sqrt{(1 + var(\\hat{y}))}\n",
    "$$\n",
    "Here we have an extra $1$ in $\\sqrt{\\cdot}$ since future value observation are supposed to be $x\\hat \\beta + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51776a55-4ee0-431f-8c20-bdc55a683718",
   "metadata": {},
   "source": [
    "### R code for manually calculating CI and PI given a predicted value x = new.x, dataframe = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d7bd9-b866-480f-88d6-3002cf779df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data that's easy to use\n",
    "X = cbind(1, data$xcols) # our design matrix X (add a intercept column, make sure y is not included)\n",
    "#print(X)\n",
    "y = data$ycol\n",
    "\n",
    "# Compute LSE manually \n",
    "invXTX = solve(t(X) %*% X)\n",
    "XTy = t(X) %*% y\n",
    "beta = invXTX %*% XTy\n",
    "# round to 3 decimals and check\n",
    "print(round(beta, 3))\n",
    "\n",
    "# Predict response for new observation\n",
    "new.X = (some number)\n",
    "(y_pred = beta[1] + beta[2]*new.X )\n",
    "\n",
    "# Verify y_pred using R function\n",
    "predict(fit, newdata=data.frame(temp=new.X))\n",
    "\n",
    "# Compute confidence interval\n",
    "new.Xvec = c(1, new.X)\n",
    "N = nrow(data)\n",
    "k = ncol(X) - 1\n",
    "# compute sd estimate\n",
    "sigma2 = t(y-X%*%beta)%*%(y-X%*%beta) / (N-k-1) \n",
    "se.conf = sqrt(sigma2*(t(new.Xvec)%*%invXTX%*%new.Xvec))\n",
    "# compute t quantile\n",
    "cv = qt(0.025, N-k-1, lower.tail=FALSE)\n",
    "# construct CI\n",
    "c(pred-cv*se.conf, pred+cv*se.conf)\n",
    "\n",
    "# Verify CI using R function\n",
    "predict(fit, newdata=data.frame(temp=new.X),\n",
    "        interval=\"confidence\")\n",
    "\n",
    "# Compute prediction interval\n",
    "se.pred = sqrt(sigma2*(1+t(new.Xvec)%*%invXTX%*%new.Xvec))\n",
    "c(pred-cv*se.pred, pred+cv*se.pred)\n",
    "\n",
    "# Verify PI using R function\n",
    "predict(fit, newdata=data.frame(temp=new.X),\n",
    "        interval=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d0656-1aa9-4cb0-9aad-5ac0b953d00c",
   "metadata": {},
   "source": [
    "Let us assume the knowledge that the least square estimator (may leave it as an assignment) is given by\n",
    "$$\n",
    " \\hat {\\mathbf \\beta} = ( {\\bf X}^T  {\\bf X})^{-1}  {\\bf X}^T {\\bf y}.\n",
    "$$\n",
    "\n",
    "\n",
    "Given this knowledge, we find\n",
    "\\begin{align*}\n",
    "{\\bf X}^T ( {\\bf y} - {\\bf X} \\hat {\\mathbf \\beta} )\n",
    "& = {\\bf X}^T {\\bf y} - {\\bf X}^T {\\bf X} ( {\\bf X}^T  {\\bf X})^{-1}  {\\bf X}^T {\\bf y}\\\\\n",
    "& = {\\bf X}^T {\\bf y} - {\\bf X}^T {\\bf y}\\\\\n",
    "&= 0.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Since ${\\bf r} = {\\bf y} - {\\bf X} \\hat {\\mathbf \\beta}$, the above conclusion can be written as ${\\bf X}^T {\\bf r} = 0$.\n",
    "\n",
    "\n",
    "* Nothing in the residual is still related to ${\\bf X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf4e37-9e11-48f8-916e-e957164251f0",
   "metadata": {},
   "source": [
    "Because from the above equation we know that ${\\bf y} - {\\bf X} \\hat {\\mathbf \\beta} = 0$ therefore we can also write that equation as $\\bar{\\bf y} - \\bar{\\bf X} \\hat {\\mathbf \\beta}=0$ because the first column of the matrix X are all 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a5815-c6ce-4a74-be33-46410717a621",
   "metadata": {},
   "source": [
    "We may write\n",
    "\\begin{align*}\n",
    "{\\bf y} - \\bar{\\bf y}\n",
    "& = ({\\bf y} - \\bf X \\hat {\\mathbf \\beta})\n",
    "   + (\\bf X \\hat {\\mathbf \\beta} - \\bar{\\bf y})\\\\\n",
    "& = ({\\bf y} - \\bf X \\hat {\\mathbf \\beta})\n",
    "+ (\\bf X - \\bar{\\bf X}) \\hat {\\mathbf \\beta}.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "With this decomposition, we find\n",
    "\\begin{align*}\n",
    "({\\bf y} - \\bar{\\bf y})^T ({\\bf y} - \\bar{\\bf y})\n",
    "& = \n",
    "({\\bf y} - \\bf X \\hat {\\mathbf \\beta})^T({\\bf y} - \\bf X \\hat {\\mathbf \\beta})\n",
    " + \n",
    "\\hat {\\mathbf \\beta}^T (\\bf X - \\bar{\\bf X})^T (\\bf X - \\bar{\\bf X}) \\hat {\\mathbf \\beta}\\\\\n",
    "& = \n",
    "({\\bf y} - \\hat{\\bf y})^T({\\bf y} - \\hat{\\bf y})\n",
    " + \n",
    "(\\hat{\\bf y} - \\bar{\\bf y} )^T(\\hat{\\bf y} - \\bar{\\bf y} )\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d39156-7806-4eb6-9d79-0188c83164f4",
   "metadata": {},
   "source": [
    "Watch closely on the decomposition:\n",
    "\\begin{align*}\n",
    "({\\bf y} - \\bar{\\bf y})^T ({\\bf y} - \\bar{\\bf y})\n",
    "& =  \n",
    "\\hat {\\mathbf \\beta}^T (\\bf X - \\bar{\\bf X})^T (\\bf X - \\bar{\\bf X}) \\hat {\\mathbf \\beta}\n",
    "+\n",
    "({\\bf y} - \\bf X \\hat {\\mathbf \\beta})^T({\\bf y} - \\bf X \\hat {\\mathbf \\beta})\n",
    "\\end{align*}\n",
    "or it is\n",
    "\\begin{align*}\n",
    "({\\bf y} - \\bar{\\bf y})^T ({\\bf y} - \\bar{\\bf y})\n",
    "& = (\\hat {\\bf y} - \\bar {\\bf y})^T (\\hat {\\bf y} - \\bar {\\bf y})\n",
    "+ {\\bf r}^T {\\bf r}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "* the LHS is the total variation in ${\\bf y}$.\n",
    "\n",
    "\n",
    "* the first term the RHS the variation in $\\hat {\\bf y}$.\n",
    "\n",
    "\n",
    "* the second term is the variation in residual ${\\bf r}$.\n",
    "\n",
    "\n",
    "This decomposition results in the analysis of variance table (ANOVA):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd22c2-0ac4-4d72-9a4d-8ce5dc6b0984",
   "metadata": {},
   "source": [
    "\\begin{matrix}\n",
    "\\mbox{Source} & \\mbox{Df} & \\mbox{SS} & \\mbox{MSS} & \\mbox{F} \\\\\n",
    "\\mbox{Regr} & k & \n",
    "(\\hat {\\bf y} - \\bar {\\bf y})^T (\\hat {\\bf y} - \\bar {\\bf y}) \n",
    "&  (\\hat {\\bf y} - \\bar {\\bf y})^T (\\hat {\\bf y} - \\bar {\\bf y}) /k \\\\\n",
    "\\mbox{Residual/error} & N-k-1 & \n",
    "({\\bf y}-{\\bf X}\\hat{\\bf \\beta})^T({\\bf y}-{\\bf X}\\hat{\\bf \\beta}) &\n",
    "({\\bf y}-{\\bf X}\\hat{\\bf \\beta})^T({\\bf y}-{\\bf X}\\hat{\\bf \\beta})/(N-k-1) & \\\\\n",
    "Total & N-1 & {\\bf y}^T{\\bf y}- \\bar{\\bf y}^T\\bar{\\bf y}\n",
    "\\end{matrix}\n",
    "\n",
    "\n",
    "The top-right entry of F should be\n",
    "$$\n",
    "F = \n",
    "\\frac{(\\hat {\\bf y} - \\bar {\\bf y})^T (\\hat {\\bf y} - \\bar {\\bf y}) /k }\n",
    "{({\\bf y}-{\\bf X}\\hat{\\bf \\beta})^T({\\bf y}-{\\bf X}\\hat{\\bf \\beta})/(N-k-1)}\n",
    "=\\dfrac{MSS_{regr}}{MSS_{error}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd081a2-e449-4ebf-bc81-d4c64fce6440",
   "metadata": {},
   "source": [
    "$$ \n",
    " T = \\frac{\\hat{\\beta_j}}{se(\\hat{\\beta_j})} = \\frac{\\hat{\\beta_j}}{\\sqrt{\\hat{\\sigma}^2(X^TX)_{jj}^{-1}}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    " {se(\\hat{\\beta_j})} ={\\sqrt{\\hat{\\sigma}^2(X^TX)_{jj}^{-1}}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = MSS error\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87618f-091b-4633-a012-a19755aecde7",
   "metadata": {},
   "source": [
    "How to know whether it is a good fitting?\n",
    "\n",
    "$$\n",
    "R^2 \n",
    "= \\frac{ \n",
    "(\\hat{\\bf y}-\\bar{\\bf y})^T(\\hat{\\bf y}-\\bar{\\bf y})}\n",
    "{({\\bf y} - \\bar {\\bf y})^T ({\\bf y} - \\bar {\\bf y}) }.\n",
    "$$\n",
    "\n",
    "\n",
    "if $R^2$ big then it is a  good fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98dec50-1f47-4ac7-b126-f325f4d07b30",
   "metadata": {},
   "source": [
    "### Variance of the experiment error \n",
    "\n",
    "We use the residual mean square to estimate $\\sigma^2$:\n",
    "$$\n",
    "\\hat \\sigma^2 \n",
    "= \n",
    "\\frac{ \n",
    "{\\bf r}^T {\\bf r}}{N-k-1}\n",
    "=\n",
    "\\frac{\n",
    "({\\bf y}-\\hat{\\bf y})^T({\\bf y}-\\hat{\\bf y})}{(N-k-1)}.\n",
    "$$\n",
    "\n",
    "\n",
    "* If $\\hat {\\bf \\beta} = {\\bf \\beta}$, \n",
    "we would have ${\\bf r} = {\\bf \\epsilon}$. \n",
    "* The estimator is explained by $var(\\epsilon_i) = \\sigma^2$ \n",
    "according to the model assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ec999-7ca5-4473-931c-ff5139a55370",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbcd2b65-8974-4d65-ba9a-d9e05ea9d17a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 samples(2.2)\n",
    "### Two-sided alternative (we want to know if there is a difference in the compared groups):\n",
    "Consider the problem of testing for two-sided alternative\n",
    "$$\n",
    "H_0: \\mu_1 = \\mu_2;  \\mbox{ vs } H_a: \\mu_1 \\neq \\mu_2.\n",
    "$$\n",
    "\n",
    "\n",
    "Let us do it under the assumptions that two samples\n",
    "are independent, each sample is made of iid observations\n",
    "such that\n",
    "$Y_{ij} \\sim N( \\mu_i; \\sigma^2)$. -> note no subscript on variance, every observation from set 1 and 2 have equal variance (assumption)\n",
    "\n",
    "Question we want to answer: do they have different means?\n",
    "\n",
    "\n",
    "* Elements in the assumption: (1) independence, (2) normality, and (3) equal variance.\n",
    "\n",
    "\n",
    "### Standard data analysis\n",
    "\n",
    "Compute the sample means and variances\n",
    "\n",
    "$$\n",
    "\\bar y_1 = n_1^{-1} \\sum_{i=1}^{n_1} y_{1i}; ~~~\n",
    "\\bar y_2 = n_2^{-1} \\sum_{i=1}^{n_2} y_{2i}.\n",
    "$$\n",
    "and\n",
    "\n",
    "$$\n",
    "s_1^2 = (n_1-1)^{-1} \\sum_i (y_{1i} - \\bar y_1)^2; ~~\n",
    "s_2^2 = (n_2-1)^{-1} \\sum_i (y_{2i} - \\bar y_2)^2.\n",
    "$$\n",
    "\n",
    "Compute **pooled variance** estimator (note that $s_1^2$ and $s_2^2$ are the variances of sample 1 and 2), ONLY FOR EQUAL VARIANCE ASSUMPTION:\n",
    "\n",
    "$$\n",
    "s^2 =\n",
    "\\frac{(n_1-1) s_1^2 + (n_2 - 1) s_2^2}{n_1 + n_2 - 2},\n",
    "$$\n",
    "\n",
    "and then the t-statistic\n",
    "$$\n",
    "T = \\frac{\\bar y_1 - \\bar y_2}{\\sqrt{(1/n_1 + 1/n_2) s^2}}.\n",
    "$$\n",
    "\n",
    "### How does df affect T-distribution\n",
    "\n",
    "As sample size increases (df -> $\\infty$), it gets closer to normal distribution.\n",
    "\n",
    "Larger df means slimmer density since variance gets smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193258ee-c70c-4ef9-9ca0-f4e1738b2f6a",
   "metadata": {},
   "source": [
    "### R-code for calculating p-value for two-sided hypothesis test (equal variance, adjust for unequal variance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60022d96-8daa-48b8-9b7f-8492a2b53f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssPool = ((n1 - 1)*var(yy) + (n2 - 1)*var(xx))/ (n1 + n2 - 2)\n",
    "\n",
    "T_obs = (mean(xx) - mean(yy))/((1/n1 + 1/n2)*ssPool)^.5\n",
    "\n",
    "pValue = 2*(1 - pt(abs(T_obs), df = n1 + n2 - 2))\n",
    "    ## two sided: key words: more extreme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca78ecf-3e84-4fd8-94b0-543d11e37fb6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### One-sided alternative (we want to know if there is a difference between 2 groups, and ALSO if it is positive or negative (direction)): \n",
    "  \n",
    "  \n",
    "* The hypotheses are $ H_0: \\mu_1 = \\mu_2; \\mbox{ vs } H_1: \\mu_1 > \\mu_2$.\n",
    "\n",
    "\n",
    "* The best practice is to ensure that $T$ is **lined up** with $H_1$.\n",
    "\n",
    "\n",
    "* In this example, $H_1$ states $\\mu_1 - \\mu_2 > 0$. \n",
    "\n",
    "So we calculate\n",
    "\n",
    "$$T =\\frac{ (\\hat{\\mu}_1 - \\hat{\\mu}_2)} {\\sqrt{ (1/n_1+1/n_2) s^2}}$$\n",
    "\n",
    "where $\\hat{\\mu}_1 = \\bar{y}_1$ and $\\hat{\\mu}_2 = \\bar{y}_2$.\n",
    "    \n",
    "    \n",
    "* Reject $H_0$ in favour of $H_1$ when $P( T > T_{obs})$ is below the nominal level (the usual choice is 5\\%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae07df83-e093-4d95-95b2-3ac0fe73d6b4",
   "metadata": {},
   "source": [
    "### R-code for calculating p-value for one-sided hypothesis test (equal variance, adjust for unequal variance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ded16-a9cf-479c-ba01-dc21763c746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssPool = ((n1 - 1)*var(yy) + (n2 - 1)*var(xx))/(n1 + n2 - 2)\n",
    "\n",
    "T_obs = (mean(xx) - mean(yy))/sqrt((1/n1+1/n2)*ssPool)\n",
    "\n",
    "pValue = pt(T_obs, df = n1 + n2 - 2, lower.tail = F)  \n",
    "      ## upper side is calculated\n",
    "\n",
    "###check your work (remove alternative parameter for two-sided test)\n",
    "## R programming language can do it in one strike.\n",
    "\n",
    "t.test(xx, yy, alternative = \"greater\", var.equal = T)\n",
    "\n",
    "t.test(xx, yy, alternative = \"greater\", var.equal = F)\n",
    "## analysis under unequal variance assumption gives very similar p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8462675-f0d3-4a8b-94a7-3eccc5b249dc",
   "metadata": {},
   "source": [
    "### Statistical reasoning\n",
    "\n",
    "In statistics, we examine how much built-in variation is in $\\bar y_1 - \\bar y_2$.\n",
    "\n",
    "\n",
    "Under the model assumption, we have\n",
    "\n",
    "$$ Var(\\bar y_1 - \\bar y_2) = (1/n_1 + 1/n_2) \\sigma^2.$$\n",
    "\n",
    "\n",
    "In applications, we are not given the value of $\\sigma^2$.\n",
    "However, the pooled variance estimator $s^2$ is a good estimate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c4b02-b6a6-4d43-b301-548c7f5777af",
   "metadata": {},
   "source": [
    "### Note: t test statistic is constructed by standardizing the difference in means under the null, i.e., dividing by the standard deviation. A smaller variance will lead to a larger test statistic value.\n",
    "\n",
    "The underlying distribution of the test statistic doesn't change with the options given in the question and so the smaller variance strictly increases the power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c0c4cd-ee69-42a6-a993-fbff2cf2d03b",
   "metadata": {},
   "source": [
    "## Equal Variance\n",
    "\n",
    "Because of this, we get a good metric:\n",
    "$$\n",
    "T = \\frac{\\bar y_1 - \\bar y_2}{\\sqrt{(1/n_1 + 1/n_2) s^2}}.\n",
    "$$\n",
    "\n",
    "\n",
    "Statistic theory reveals that its distribution when $H_0$ is true is\n",
    "t-distribution with degrees of freedom **df** $n_1 + n_2 - 2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88252da-2fc6-4716-8c92-18db752e523a",
   "metadata": {},
   "source": [
    "## Unequal variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5ee31-35b2-468c-936e-b0e9db601ce0",
   "metadata": {},
   "source": [
    "### Effect of unequal variance (cannot use pooled variance as it does not make sense)\n",
    "\n",
    "* One remedy to t-test in this case is to change the t-statistic itself to\n",
    "\n",
    "$$\n",
    "T = \\frac{(\\bar y_1 - \\bar y_2)}{\\sqrt{(s^2_1/n_1 + s^2_2/n_2)}}\n",
    "$$\n",
    "\n",
    "so that the denominator matches the variance of the numerator even if $\\sigma_1^2 \\neq \\sigma_2^2$.\n",
    "\n",
    "\n",
    "* Yet even after this remedy, $T$ still does not have t-distribution.\n",
    "\n",
    "\n",
    "* The distribution of $T$ depends on the size of $\\sigma_2/\\sigma_1$ which is unknown in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5939d-b118-4333-bfa6-e88b0faea8b5",
   "metadata": {},
   "source": [
    "### Welch's t-test remedy (how to calculate df for unequal variance only)\n",
    "\n",
    "* Use the new definition of $T$.\n",
    "\n",
    "\n",
    "* **PRETEND** $T$ has a t-distribution with $f$ degrees of freedom:\n",
    "\n",
    "$$\n",
    "\\frac{1}{f} \n",
    "= \\left ( \\frac{R}{1+R} \\right )^2 \\frac{1}{n_1 - 1} \n",
    "+ \n",
    "\\frac{1}{(n_2-1)(1+R)^2}\n",
    "$$\n",
    "\n",
    "where $R = (s_1^2/n_1)/(s_2^2/n_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97ad92-6fe3-4141-a24d-22e809cf1cb7",
   "metadata": {},
   "source": [
    "### R code for calculating p value for UNEQUAL VARIANCE assumption (one-sided hypothesis test, using Welch's t-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df85b8d-ff59-4fbe-ad2d-f78856b2d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Welch's t-stat\n",
    "T_obs = (mean(xx) - mean(yy))/sqrt(var(y1)/n1+var(y2)/n2)\n",
    "\n",
    "#calculate df using Welch's eq:\n",
    "R <- (var(y1)/n1)/(var(y2)/n2)\n",
    "df_uneq <- 1/(((R/(1+R))^2 * (1/(n1-1)) + 1/((n2 - 1)*(1+R)^2)))\n",
    "\n",
    "p2 <- 2*pt(abs(T_obs), df_uneq, lower.tail = FALSE)\n",
    "\n",
    "#check p2\n",
    "test.res2 = t.test(y1, y2)\n",
    "test.res2$p.value\n",
    "#reject null hypothesis if p2 < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3ba8e-dd38-44e4-98f6-b7b2257b181c",
   "metadata": {},
   "source": [
    "### The effect of increasing sample size (repetition)\n",
    "\n",
    "* Larger $m, n$ leads to larger observed $|T|$, $|T_{obs}|$, if $\\mu_1 \\neq \\mu_2$.\n",
    "\n",
    "\n",
    "* Larger $|T_{obs}|$ leads to smaller p-value and hence increased power of detecting the fact that $\\mu_1 \\neq \\mu_2$.\n",
    "\n",
    "\n",
    "* If $\\mu_1 = \\mu_2$, the size of $T$ is unaffected by $n_1, n_2$. Hence, type I error remains under control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59bf4c-5dc3-43fb-abea-3fe0c7c6a3e1",
   "metadata": {},
   "source": [
    "### F-test in the two-sample problem (check whether $\\sigma_1 = \\sigma_2$ is a reasonble assumption)\n",
    "\n",
    "* Obtain $F_{obs} = s_1^2/s_2^2$. \n",
    "\n",
    "* Both its value close to 0 or extremely large is suggestive to the violation of $H_0: \\sigma_1 = \\sigma_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f7b73-890e-4b77-b2d1-4e55b0c554ea",
   "metadata": {},
   "source": [
    "# 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba565fd8-2704-4a77-bb95-07725f91f453",
   "metadata": {},
   "source": [
    "### Our p-value for two-sided alternative, randomization test\n",
    "\n",
    "We use randomization test to avoid the normality assumption (helps with it) and prevent the influence of lurk variables.\n",
    "\n",
    "* Let $d_{obs} = \\bar y_1 - \\bar y_2$: the observed difference in two sample means. (We used $d^*$ in the last slide).\n",
    "\n",
    "* Let $d_i$ be the value of $\\bar y_1 - \\bar y_2$ based on permuted observations, $i=1, 2, \\ldots, {n_1+n_2 \\choose n_1}$.\n",
    "\n",
    "* Let $c_1= n\\{|d_i| > |d_{obs}|\\}$, and $c_2 =n \\{|d_i| = |d_{obs}|\\}$.\n",
    "\n",
    "We define the p-value as\n",
    "*  pvalue $= (c_1 + 0.5c_2)/{n_1+n_2 \\choose n_1} $.\n",
    "\n",
    "We reject $H_0$ if the p-value is smaller than 0.05 (or another pre-agreed level)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34132d2a-6f45-492e-9985-a7c501300157",
   "metadata": {},
   "source": [
    "### Code for performing randomization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1942f1-fda9-4b54-8f9e-f7fa57cb075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = choose(n1+n2, n1)\n",
    "mm = abs(mean(yy) - mean(xx))\n",
    "zz = c(xx, yy)\n",
    "zbar = mean(zz)\n",
    "dd = combn(zz, n2, FUN=mean)\n",
    "dd = abs(dd + (n2*dd - (n1+n2)*zbar)/10)\n",
    "pp = (sum(dd > mm) + 0.5*sum(dd== mm)) / total   # p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be55652-bc7e-4e1a-b6ac-d7d614b1d619",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Single Factor with multiple levels\n",
    "\n",
    "The T-test is mostly used to compare the effect of two treatments. We now consider the situation where more than two treatments derived from a single factor are being investigated.\n",
    "\n",
    "To be called a **single factor** experiment, these treatments should intrinsically be connected.\n",
    "\n",
    "For example, fertilizers of various kinds or mixtures; the temperature at different levels, the medicine of several kinds, or a medicine at various dosages.\n",
    "\n",
    "Linear model proposed:\n",
    "\n",
    "$$\n",
    "y_{ij} = \\eta + \\tau_i + \\epsilon_{ij}\n",
    "$$\n",
    "$\\eta$ is the overall mean, $\\tau_i$ is the mean response from the $i$th treatment after subtracting the overall mean. The error term $\\epsilon_{ij}$ is what cannot be explained by **the treatment effect** $\\tau_i$.\n",
    "\n",
    "$$\n",
    "\\epsilon_{ij} \\sim N(0, \\sigma^2)\n",
    "$$\n",
    "and they are independent of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ab72f-b4ff-4229-8e3c-b6078add798b",
   "metadata": {},
   "source": [
    "### Intuitive but easily justified estimates\n",
    "\n",
    "Let\n",
    "\n",
    "* $\\bar{y}_{i \\cdot} = (y_{i1} + y_{i2} + \\cdots + y_{i n_i})/n_i$;\n",
    "\n",
    "\n",
    "* $\\bar{y}_{\\cdot j} = (y_{1j} + y_{2j} + \\cdots + y_{kj})/k$;\n",
    "\n",
    "\n",
    "* $\\bar{y}_{\\cdot \\cdot} = \\sum_{i,j} y_{ij}/{N}$.\n",
    "\n",
    "\n",
    "\n",
    "The following estimates of parameters are generally used:\n",
    "\n",
    "\n",
    "* $\\hat \\eta = \\bar{y}_{..}; ~~~\\hat \\tau_i = \\bar{y}_{i \\cdot} - \\bar{y}_{..}$.\n",
    "\n",
    "\n",
    "Each observed value can be decomposed as\n",
    "\n",
    "$\n",
    "y_{ij} \n",
    " = \\bar{y}_{..} + (\\bar{y}_{i \\cdot} - \\bar{y}_{..}) + (y_{ij} - \\bar{y}_{i \\cdot})\n",
    " = \\hat \\eta + \\hat \\tau_i + r_{ij}.\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1f2ba-39a6-4ca5-93e8-614caab9c721",
   "metadata": {},
   "source": [
    "## The question this experiment aims to answer\n",
    "\n",
    "\n",
    "Do these treatments have different effects in terms of the brightness of the pulp sheets they produce?\n",
    "\n",
    "\n",
    "In statistical language: test the hypothesis that $H_0: \\tau_1 = \\tau_2 = \\cdots = \\tau_k = 0$.\n",
    "\n",
    "\n",
    "* If their sum is 0 and they are equal, then all of them must be zero.\n",
    "\n",
    "\n",
    "#### Whether they are all zero or not is best reflected in the size of\n",
    "\n",
    "SS$_{trt} = n_1\\hat \\tau_1^2 + n_2\\hat \\tau_2^2 + \\cdots + n_k\\hat\\tau_k^2 \n",
    "= \\sum_{i=1}^k n_i(\\bar y_{i\\cdot} - \\bar{y}_{\\cdot \\cdot})^2.$\n",
    "\n",
    "\n",
    "* We call this quantity the treatment sum of squares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a5e4d-cb2b-43ad-a3bd-2719b05fcf66",
   "metadata": {},
   "source": [
    "## F-test/Distribution\n",
    "Is $\\mbox{SS}_{trt}$ sufficiently large to justify rejecting $H_0$?\n",
    "\n",
    "* We compare its size against the residual sum of squares\n",
    "\n",
    "$\\mbox{SS}_{err} = \\sum_{i=1}^k \\sum_{j=1}^{n_i} (y_{ij} - \\bar y_{i\\cdot})^2$\n",
    "This leads to the Analysis of Variance Table.\n",
    "\n",
    "$F = \\mbox{MSS}_{Trt}/\\mbox{MSS}_{err}$ has an F-distribution with $k-1$ and $N-k$ degrees of freedom when $H_0$ is true.\n",
    "\n",
    "An unusually large $F_{obs}$, indicates the treatment sum of squares is likely inflated due to unequal $\\tau_i$ values.\n",
    "\n",
    "Hence, we compute p-value as $P( F > F_{obs})$ and reject $H_0$ when the p-value is small (than 5%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0350774-1634-4425-b292-34465c1138f7",
   "metadata": {},
   "source": [
    "## ANOVA for One-way layout\n",
    "\n",
    "\n",
    "\\begin{matrix}\n",
    "\\mbox{Source} & \\mbox{DF} & \\mbox{SS}  & \\mbox{MSS} & \\mbox{F} \\\\\n",
    "\\mbox{Trt} & k-1\n",
    "& \n",
    "\\sum_{i=1}^k n_i(\\bar y_{i \\cdot}-\\bar y_{\\cdot\\cdot})^2\n",
    "&\n",
    "\\mbox{SS}_{trt}/(k-1) & * \\\\\n",
    "\\mbox{Resid/Error} & N-k\n",
    "& \n",
    "\\sum_{i=1}^k \\sum_{j=1}^{n_i}(y_{i j} - \\bar y_{i \\cdot})^2  -> (SS_{tot} - SS_{trt})\n",
    "&\n",
    "\\mbox{SS}_{err}/(N-k)& \\\\\n",
    "\\mbox{Total} & N-1 &\n",
    "\\sum_{i=1}^k \\sum_{j=1}^{n_i}(y_{i j} - \\bar y_{\\cdot \\cdot})^2\n",
    "&\n",
    "SS_{tot} / (N-1)\n",
    "\\end{matrix}\n",
    "\n",
    "\n",
    "\n",
    "The F-statistic is defined to be\n",
    "$F = \\mbox{MSS}_{trt}/\\mbox{MSS}_{err}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bb0bb-4adc-4ca4-8ac2-52126d458e04",
   "metadata": {},
   "source": [
    "## Equations/Sample code to calculate ANOVA table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809980d-adcb-4ff7-9cff-02cf1519f761",
   "metadata": {},
   "source": [
    "#### Sum of Squares for treatment \n",
    "\n",
    "\n",
    "* SS$_{trt}=\\sum_{i=1}^k n_i(\\bar y_{i \\cdot}-\\bar y_{\\cdot\\cdot})^2$\n",
    "\n",
    "\n",
    "* MSS $_{trt}=\\mbox{SS}_{trt}/(k-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebdb61-c764-4af4-b4dc-4118e6b12c6f",
   "metadata": {},
   "source": [
    "#### Sum of Squares for treatment \n",
    "\n",
    "* SS$_{trt}=\\sum_{i=1}^k n_i(\\bar y_{i \\cdot}-\\bar y_{\\cdot\\cdot})^2$\n",
    "\n",
    "* MSS $_{trt}=\\mbox{SS}_{trt}/(k-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95012100-caf7-4d52-856e-0d3df7d8b700",
   "metadata": {},
   "source": [
    "#### Sum of Squares for error\n",
    "\n",
    "\n",
    "* SS$_{err} =\\sum_{i=1}^k \\sum_{j=1}^{n_i} ( y_{i j} - \\bar y_{i \\cdot})^2$ \n",
    "\n",
    "\n",
    "* MSS$_{err}$ = SS$_{err}/(N-k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd17091-73fd-4fd0-bc58-113bf1af35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = c(...) ; bb = c(...) ; cc = c(...) ; dd = c(...) ; \n",
    "yy = c(aa, bb, cc, dd)\n",
    "\n",
    "aabar = mean(aa); bbbar = mean(bb); ccbar = mean(cc); ddbar = mean(dd); \n",
    "yybar = mean(yy)\n",
    "\n",
    "SS.trt = n*((aabar - yybar)^2+(bbbar - yybar)^2 + (ccbar - yybar)^2 + (ddbar - yybar)^2)\n",
    "MSS.trt = SS.trt/(k-1)\n",
    "\n",
    "print(c(aabar, bbbar, ccbar, ddbar)) ; print(mean(yy)) ; print(SS.trt) ; print(MSS.trt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c290173-1208-4b17-9ceb-fcd68534e8f6",
   "metadata": {},
   "source": [
    "#### Sum of Squares for error\n",
    "\n",
    "* SS$_{err} =\\sum_{i=1}^k \\sum_{j=1}^{n_i} ( y_{i j} - \\bar y_{i \\cdot})^2$ \n",
    "\n",
    "* MSS$_{err}$ = SS$_{err}/(N-k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5f88d-8e53-461e-8e2e-ba0f9a94257d",
   "metadata": {},
   "source": [
    "#### Total Sum of Squares/F-value/P-value:\n",
    "\n",
    "\n",
    "SS$_{tot} = \\sum_{i=1}^k \\sum_{j=1}^{n_i} ( y_{i j} - \\bar y_{\\cdot \\cdot})^2$\n",
    "\n",
    "\n",
    "Remark: it is not used for inference. It should equal the sum of the other two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579affc-240d-4752-a57b-d90b5c73ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS.e = sum((aa - aabar)^2)+sum((bb-bbbar)^2)+sum((cc-ccbar)^2) + sum((dd-ddbar)^2)\n",
    "\n",
    "MSS.e = SS.e/(N-k)\n",
    "\n",
    "print(SS.e);  print(MSS.e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba9aeb-7549-4534-b662-078087805ccb",
   "metadata": {},
   "source": [
    "#### Total Sum of Squares/F value/p-value:\n",
    "\n",
    "SS$_{tot} = \\sum_{i=1}^k \\sum_{j=1}^{n_i} ( y_{i j} - \\bar y_{\\cdot \\cdot})^2$\n",
    "\n",
    "Remark: it is not used for inference. It should equal the sum of the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c9f6b-58e0-4348-a462-c4195e6ed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS.tot = sum( (yy - mean(yy))^2)\n",
    "\n",
    "print(SS.tot)\n",
    "\n",
    "#F-value\n",
    "f = MSS.trt/MSS.e\n",
    "\n",
    "#p-value\n",
    "p.value = pf(f, k-1, N-k, lower.tail=F)\n",
    "\n",
    "#Calculate f stat\n",
    "qf(1-alpha, k-1, n-k)\n",
    "#For F test, if f stat > f critical value, results statistically significant.\n",
    "#may not be necessary to calculate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f865104-b7b9-4670-99ca-4bbbd916b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check your ans:\n",
    "\n",
    "## standard R function for one-way anova\n",
    "## we first organize the data into required data.frame format.\n",
    "trt = c(rep(\"aa\", n), rep(\"bb\", n), rep(\"cc\", n), rep(\"dd\", n))\n",
    "pulp.data = data.frame(yy, trt)\n",
    "\n",
    "SS.tot = sum((yy-mean(yy))^2) \n",
    "## extra calculation for other purposes.\n",
    "\n",
    "pulp.aov <- aov(yy ~ trt, pulp.data)\n",
    "summary(pulp.aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d1a83-5434-463f-9b7c-ae39c0324420",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdde29-ae53-4dc5-a13b-56b91f95b0f5",
   "metadata": {},
   "source": [
    "### Note: Tukey’s method and the Bonferroni method CI, the intervals that does NOT contain 0 means that the corresponding group has significantly different mean.\n",
    "\n",
    "ie. If the interval excludes 0, then the difference of the means of the two groups is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a86207-8183-4aab-9a8a-722cc6851fcd",
   "metadata": {},
   "source": [
    "### Applying this idea for one-way layout\n",
    "\n",
    "### Bonferroni - used to control family-wise type I error, proof in lecture 3.1 sub\n",
    "\n",
    "* there are $k' = k(1-k)/2$ (k choose 2) parameters of interest ($\\mu_i - \\mu_j$) \n",
    "    in one-way layout.\n",
    "\n",
    "* for two-sided simultaneous CIs, set $\\alpha' = \\alpha/k'$.\n",
    "* The Bonferroni method rejects any $H_{ij}: \\mu_i = \\mu_j$ only if\n",
    "$\n",
    "|t_{ij}| > t( 1-\\alpha'/2; N-k).\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb820bd2-6716-4e1f-8d0f-e43ba2cad810",
   "metadata": {},
   "source": [
    "* the t-statistic for this purpose \n",
    "\n",
    "$$\n",
    "\\frac{ (\\bar y_{j \\cdot} - \\bar y_{i \\cdot})-(\\mu_j - \\mu_i) }{\\sqrt{ (1/n_i + 1/n_j) \\hat \\sigma^2}}.\n",
    "$$\n",
    "\n",
    "\n",
    "* the two-sided simultaneous CIs for $\\mu_j - \\mu_i$ derived from it:\n",
    "\n",
    "$$\n",
    "(\\bar y_{j \\cdot} - \\bar y_{i \\cdot})\n",
    "\\pm t(1-\\alpha'/2, N-k) ~ \\hat \\sigma \\sqrt{1/n_i + 1/n_j}.\n",
    "$$\n",
    "\n",
    "\n",
    "* the error variance $\\hat \\sigma^2$ is estimated by MSS$_{err}$.\n",
    "\n",
    "### Variations:\n",
    "\n",
    "* When $n_i = n_j = n$, we have $\\sqrt{1/n_i + 1/n_j} = \\sqrt{2/n}$.\n",
    "\n",
    "\n",
    "* Logic: transfer $\\theta \\to \\mu_j - \\mu_i$, \n",
    "$\\hat \\theta_i \\to (\\bar y_{j \\cdot} - \\bar y_{i \\cdot})$, \n",
    "and \n",
    "$\\widehat{var}(\\hat \\theta) \\to (1/n_i + 1/n_j) \\hat \\sigma^2$.\n",
    "\n",
    "\n",
    "* Simultaneous one-sided CIs have form\n",
    "\n",
    "$$\n",
    "(\\bar y_{j \\cdot} - \\bar y_{i \\cdot})\n",
    "\\pm t(1-\\alpha', N-k) ~ \\hat \\sigma \\sqrt{1/n_i + 1/n_j}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70260716-0cdb-450a-96c2-8da35e5e4b08",
   "metadata": {},
   "source": [
    "### Tukey's method is one of many possible remedies. \n",
    "\n",
    "\n",
    "* We confine ourselves in the context of one-way layout.\n",
    "\n",
    "\n",
    "* The difference in means are estimated by \n",
    "    $\\bar y_{i\\cdot}-\\bar y_{j \\cdot}$\n",
    "\n",
    "\n",
    "* The key quantity is given by\n",
    "\n",
    "$$ t_{ij} = \n",
    "\\frac{(\\bar y_{i\\cdot}-\\bar y_{j \\cdot}) - (\\mu_i - \\mu_j)}\n",
    "{\\sqrt{ (1/n_i + 1/n_j)s^2}}.\n",
    "$$\n",
    "\n",
    "\n",
    "* A key quantity for testing $\\mu_i - \\mu_j = 0$ for all $i, j$\n",
    "is \n",
    "\n",
    "$$\n",
    "t^* = \\sqrt{2} \\max \\{ |t_{ij}| \\}\n",
    "$$\n",
    "\n",
    "> with $\\mu_i - \\mu_j = 0$ when calculating $t_{ij}$.\n",
    "\n",
    "\n",
    "**Pay no attention to $sqrt{2}$ here, it is statistically irrelevant at this moment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdaec9e-1b4a-41f2-907a-ab688aec3616",
   "metadata": {},
   "source": [
    "* Reject null hypothesis that all treatments have equal mean when \n",
    "$$|t_{ij}| > qtukey(1- \\alpha; k, N-k)/\\sqrt{2}$$.\n",
    "\n",
    "\n",
    "* The null rejection rate is given by $\\alpha$.\n",
    "\n",
    "* the two-sided simultaneous CIs for $\\mu_j - \\mu_i$ derived from it:\n",
    "\n",
    "$$\n",
    "(\\bar y_{j \\cdot} - \\bar y_{i \\cdot})\n",
    "\\pm \\frac {1}{\\sqrt{2}}tukey(1-\\alpha,k, N-k) ~ \\hat \\sigma \\sqrt{1/n_i + 1/n_j}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d458e53-cd43-4d52-9c87-31e9524ecb7e",
   "metadata": {},
   "source": [
    "### Simultaneous CI by Tukey method\n",
    "\n",
    "\n",
    "We may use Tukey method to construct simultaneous CI based on the same idea:\n",
    "\n",
    "$$\n",
    "\\frac{ \\sqrt{2}|(\\hat \\tau_i - \\hat \\tau_j)-(\\tau_i - \\tau_j)|}\n",
    "{\\sqrt{(1/n_i + 1/n_j)s^2}} \\leq qtukey(1- \\alpha; k, N-k)\n",
    "$$\n",
    "> for all $i, j$.\n",
    "\n",
    "\n",
    "In particular, for the pulp example, $k=4, N=20$, the\n",
    "($\\mu_B - \\mu_D$) part of the simultaneous 95\\% CIs is given by\n",
    "\n",
    "$$\n",
    "0.62 \\pm 2.86\\times \\sqrt{1/5 + 1/5}\\times \\sqrt{0.106}\n",
    "= [ 0.03, 1.21].\n",
    "$$\n",
    "\n",
    "\n",
    "Since 0 is not in this interval, the method again finds\n",
    "the $\\mu_B - \\mu_D \\neq 0$ at $0.05$ significance level.\n",
    "\n",
    "\n",
    "**Remark: conclusions of different methods do not have to be identical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9547690-812b-43e4-b729-209da8768726",
   "metadata": {},
   "source": [
    "## 3.3 \n",
    "### Sample size determination.\n",
    "\n",
    "* Let\n",
    "$$\n",
    "\\mbox{SS}_{err} = \\sum_{i=1}^k \\sum_{j=1}^{n_i} (y_{ij} - \\bar y_{i \\cdot})^2\n",
    "$$\n",
    "\n",
    ">be the sum of squares due to error terms. \n",
    "\n",
    "\n",
    "* We will show that $\\sum_{j=1}^{n_i} (y_{ij} - \\bar y_{i \\cdot})^2/\\sigma^2$ has a chisquare distribution with df = $n_i-1$.\n",
    "\n",
    "\n",
    "* This further implies $E[\\sum_{j=1}^{n_i} (y_{ij} - \\bar y_{i \\cdot})^2] = (n_i-1) \\sigma^2$.\n",
    "\n",
    "* Similarly, we have E$(\\mbox{SS}_{err}) = (N-k) \\sigma^2$.\n",
    "\n",
    "\n",
    "* Therefore, we choose\n",
    "\n",
    "\n",
    "$$\n",
    "s^2 = (N-k)^{-1} \\mbox{SS}_{err}\n",
    "$$\n",
    "\n",
    "\n",
    ">as an estimator of $\\sigma^2$. \n",
    "\n",
    "\n",
    "* We claimed that\n",
    "\n",
    "$$\n",
    "F = \\frac{\\mbox{MSS}_{trt}}{\\mbox{MSS}_{err}} = \\frac{\\mbox{MSS}_{trt}}{s^2}\n",
    "$$\n",
    "\n",
    "> has F-distribution with $k-1$ and $N-k$ degrees of freedom **when $H_0$ is true**.\n",
    "\n",
    "\n",
    "* These are basis for sample size calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e0082-f145-49b8-b44a-27358ad8c7a9",
   "metadata": {},
   "source": [
    "* Suppose that scientists hope to confirm that treatment effects are significantly different by an experiment.\n",
    "\n",
    "* Even if such a difference is real, there is no guarantee that a simple experiment will provide convincing statistical evidence.\n",
    "\n",
    "(1) As long as one cannot eliminate the randomness in the experiment,\n",
    "there is no way to make the case with a 100% guarantee.\n",
    "\n",
    "(2) The lower is the difference in treatment effects, the larger is\n",
    "the required sample size.\n",
    "\n",
    "(3) Increasing sample size (replicates) elevates the chance of detecting the difference **if there is any**.\n",
    "\n",
    "**If we believe the effect is very low, there is no point to try to confirm it**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7818d-878c-4033-8831-598e338f2d85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9d434c7-270b-402e-ba83-b55aa59c957b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f45142f-3993-482b-b9f7-7c1ca00aa7b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1607d62-ec5a-45d7-a516-ad8374300d6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b8782b4-5a10-4ad6-9cfc-42f05c1bfe1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "596b8b6b-aa7a-493b-b6ca-ca19efb094b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c20a2921-c8b2-4f02-b7b3-76b47a2530c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
